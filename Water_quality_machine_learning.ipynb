{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for complex mathematical operations\n",
    "import numpy as np \n",
    "\n",
    "#for dataframe manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# for data visulisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for implementing complex machine learning algorithm use sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc766c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"newkpcbclasswise.csv\", encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Dataset:\" , data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cfb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since missing values should not be present for a better machine learning ...find the missing value is present or not\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98726ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "# Separate majority and minority classes\n",
    "data_majority = data[data.CLASS=='B']\n",
    "data_minority_1 = data[data.CLASS=='A']\n",
    "data_minority_2 = data[data.CLASS=='C']\n",
    "data_minority_3 = data[data.CLASS=='D']\n",
    "data_minority_4 = data[data.CLASS=='E']\n",
    "data_minority_5 = data[data.CLASS=='Below E']\n",
    "\n",
    "# Upsample minority class\n",
    "data_minority_upsampled_1 = resample(data_minority_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(data_majority),    # to match majority class\n",
    "                                 random_state=1234) # reproducible results\n",
    "\n",
    "data_minority_upsampled_2 = resample(data_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(data_majority),    # to match majority class\n",
    "                                 random_state=1234) # reproducible results  \n",
    "\n",
    "data_minority_upsampled_3 = resample(data_minority_3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(data_majority),    # to match majority class\n",
    "                                 random_state=1234) # reproducible results                             \n",
    "\n",
    "\n",
    "data_minority_upsampled_4 = resample(data_minority_4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(data_majority),    # to match majority class\n",
    "                                 random_state=1234) # reproducible results  \n",
    "\n",
    "data_minority_upsampled_5 = resample(data_minority_5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(data_majority),    # to match majority class\n",
    "                                 random_state=1234) # reproducible results   \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled_1,data_minority_upsampled_2,data_minority_upsampled_3,data_minority_upsampled_4,data_minority_upsampled_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_upsampled['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f761407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove label coloumn data from the dataset to avoid cheating in case of model formation, \n",
    "# and rest dataset is stored in x variable and label is stored in y variable\n",
    "\n",
    "x=data_upsampled.drop(['CLASS','Source','Stations'],axis=1)\n",
    "y=data_upsampled['CLASS']\n",
    "\n",
    "print(\"Shape of x : \", x.shape)\n",
    "print(\"Shape of y : \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and testing dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=13)\n",
    "\n",
    "print(\"The shape of x train : \", x_train.shape)\n",
    "print(\"The shape of x test : \", x_test.shape)\n",
    "print(\"The shape of y train : \", y_train.shape)\n",
    "print(\"The shape of y test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce27bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing confusion_matrix, accuracy_score, classification_report from sklearn.metrics library to obtain confusion matrix, accuracy score and classification report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Specifiy the model\n",
    "model= GaussianNB()\n",
    "\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Now accuracy of model needed to be checked by comparing y_test with y_pred\n",
    "# Its done with the help classification report .... by importing it from sklearn library\n",
    "\n",
    "#To print confusion matrix\n",
    "plt.rcParams[\"figure.figsize\"]=(5,5)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", center=0.6)\n",
    "plt.title(\"Confusion Matrix for Naive Bayes\", fontsize=15)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "#To check accuracy\n",
    "print(\"Accuracy of the Naive Bayes Classifier model in % is:\", round(accuracy_score(y_test, y_pred)*100,2))\n",
    "\n",
    "#To print the Classification Report :\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train,y_train) #Training\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Now accuracy of model needed to be checked by comparing y_test with y_pred\n",
    "# Its done with the help classification report .... by importing it from sklearn library\n",
    "\n",
    "#To print confusion matrix\n",
    "plt.rcParams[\"figure.figsize\"]=(5,5)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "#sns.heatmap(cm, annot=True, cmap='Wistia')\n",
    "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "plt.title(\"Confusion Matrix for Decision Tree\", fontsize=15)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "#To check accuracy\n",
    "print(\"Accuracy of the Decision Tree Classifier model in % is:\", round(accuracy_score(y_test, y_pred)*100,2))\n",
    "\n",
    "#To print the Classification Report :\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1cf8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Support Vector Machine Classifier\n",
    "#from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train,y_train) #Training\n",
    "y_pred = model.predict(x_test)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "# Now accuracy of model needed to be checked by comparing y_test with y_pred\n",
    "# Its done with the help classification report .... by importing it from sklearn library\n",
    "\n",
    "#To print confusion matrix\n",
    "plt.rcParams[\"figure.figsize\"]=(5,5)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap=\"inferno\")\n",
    "plt.title(\"Confusion Matrix for Support Vector Machine Classifier\", fontsize=15)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "#To check accuracy\n",
    "print(\"Accuracy of the Support Vector Machine model  in % is:\", round(accuracy_score(y_test, y_pred)*100,2))\n",
    "\n",
    "#To print the Classification Report :\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train,y_train) #Training\n",
    "y_pred = model.predict(x_test)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Now accuracy of model needed to be checked by comparing y_test with y_pred\n",
    "# Its done with the help classification report .... by importing it from sklearn library\n",
    "\n",
    "#To print confusion matrix\n",
    "plt.rcParams[\"figure.figsize\"]=(5,5)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "#sns.heatmap(cm, annot=True, cmap='Wistia')\n",
    "#sns.heatmap(cm, annot=True,  vmin=0.0, vmax=100.0, fmt='.2f')\n",
    "sns.heatmap(cm, annot=True, cmap=\"BuPu\")\n",
    "plt.title(\"Confusion Matrix for Random Forest Classifier\", fontsize=15)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "\n",
    "#To check accuracy\n",
    "print(\"Accuracy of the Random Forest Classifier model in % is:\", round(accuracy_score(y_test, y_pred)*100,2))\n",
    "\n",
    "#To print the Classification Report :\n",
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
